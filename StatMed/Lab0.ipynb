{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Algorytmy Machine Learning w OOP Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uczenie maszynowe \n",
    "\n",
    "W ogólności rozróżniamy trzy odmiany uczenia maszynowego \n",
    "\n",
    "**Uczenie nadzorowane**\n",
    "\n",
    "**Uczenie nienadzorowane**\n",
    "\n",
    "**Uczenie przez wzmacnianie**\n",
    "\n",
    "1. Uczenie nadzorowane \n",
    "\n",
    "Jego głównym celem jest uczenie modelu za pomocą oznakowanych *danych uczących*, co pozwala przewidywać niewidoczne informacje. W tym przypadku `nadzorowane` odnosi się do zestawu próbek, w którym pożądane sygnały wyjściowe (etykiety, target) są znane. \n",
    "\n",
    "Np. Filtr antyspamowy: możemy trenować dany model stosując algorytm nadzorowanego uczenia maszynowego wobec treści oznakowanych wiadomości e-mail, dzięki czemu system jest w stanie przewidywać, czy przychodząca korespondencja zalicza się do jednej z tych dwóch kategorii. Etykiety mogą tworzyć skończony zbiór klas. Problemy realizowane w ten sposób nazywamy problemami **klasyfikacji**. W przypadku ciągłych etykiet rozwiązuje się problem **regresji**. \n",
    "\n",
    "- Klasyfikacja - najczęściej realizowany problem klasyfikacji binarnej - dobry, zły klient, W przypadku większej ilości klas realizowany jest problem klasyfikacji wieloklasowej - np. rozpoznawanie odręcznego pisma (10 cyfr, lub litery)\n",
    "\n",
    "- Regresja - przewidywanie wartości ciągłych. Pojęcie regresji pochodzi już z 1886 roku, wprowadzone zostało przez Francisa Galtona. \n",
    "\n",
    "2. Uczenie przez wzmacnianie\n",
    "\n",
    "W tym przypadku celem jest utworzenie systemu (agenta), który poprawia własną skuteczność na podstawie interakcji ze środowiskiem. Ingormacje na temat bieżącego stanu środowiska zazwyczaj zawierają także tzw. nagrody, dlatego możemy uznać uczenie przez wzmacnianie jako model powiązany z uczeniem nadzorowanym. Jendak w przypadku uczenia przez wzmacnianie sprzężeniem tym nie są poprawne, wzorce etykiety lub wartości, lecz wartość skuteczności pomiaru działania przez funkcję nagrody. Poprzez oddziaływanie ze środowiskiem regulator może wykorzystać uczenie przez wzmacnianie do trenowania szeregu działań dążących do maksymalizowania nagrody metodą prób i błędów lub rozważnego planowania. \n",
    "\n",
    "Standardowym przykładem tego typu uczenia jest silnik szachowy, lub inne gry. \n",
    "\n",
    "3. Ukryte struktury i ich odkrywanie za pomocą uczenia nienadzorowanego \n",
    "\n",
    "W przypadku uczenia nadzowrowanego znamy odpowiedź jeszcze przed rozpoczęciem trenowania danego modelu, z kolei w uczeniu przez wzmacnianie wykorzystujemy regulator do definiowania wartości nagród dla poszczególnych dziłań. Natomiast korzystając z technik uczenia nienadzorowanego mamy do czynienia z nioznakowanymi danymi lub danymi o nieznanej strukturze. Dzięli modelom uczenia nienadozrowanego jesteśmy w stanie poznawać strukturę przetrarzanych danych i uzyskiwać użyteczne informacje bez stosowania znanje zmiennej wyjściowej lub funkcji nagrody. \n",
    "\n",
    "- Grupowanie, klasteryzacja, analiza skupień \n",
    "\n",
    "nazywamy technikę badawczą analizy danych pozwalającą na organizowanie zestawów informacji w sensowne podzbiory (`klastry, grupy`) bez uprzedniej wiedzy na temat przydziału grupowego poszczególnych danych. Każdy klaster powstający w wyniku analizy definiuje zbiór obiektów wykazujących między sobą pewne podobieństwa i odróżniających się od siebie elementów umieszczonych w pozostałych grupach. Ta technika nadaje się świetnie do strukturyzowania informacji oraz wyznaczania istotnych powiązań pomiędzy danymi np. odkrywać i identyfikować grupy klientów według ich zainteresowań np w celu różnicowania programów marketingowych. \n",
    "\n",
    "- Redukcja wymiarowości w celu kompresji danych \n",
    "\n",
    "Często pracujemy z danymi wielowymiarowymi co stanowi wyzwanie w przypadku ograniczonej pojemności nośników danych oraz skuteczności obliczeniowej algorytmów uczenia maszynowego. Technika ta jest stosowana powszechnie we wstępnym przetwarzaniu cech w celu wykluczenia szumu z danych (zmniejsza skuteczność predykcji) a do tego kompresuje dane do podprzestrzeni o mniejszej liczbie wymiarów przy zachowaniu istotnej informacji. \n",
    "\n",
    "\n",
    "\n",
    "### Algorytmy uczenia maszynowego w klasyfikacji binarnej \n",
    "\n",
    "Jeden z najwcześniejszych algorytmów klasyfikacyjnych to model `Perceprtonu`.\n",
    "\n",
    "Warren McCulloch i Walter Pitts pragnęli zrozumieć mechanizm działania mózgu po to, aby zaprojektować sztuczną inteligencję i w 1943 roku zaprezentowali pierwszą koncepcję uproszczonego modelu komórki nerwowej, tzw `neuronu McCulloch-Pittsa`. \n",
    "\n",
    "`Neuronami` nazywamy wzajemnie połączone komórki nerwowe w mózgu, które są odpowiedzialne za przetwarzanie oraz przesyłanie sygnałów chemicznych i elektrycznych. \n",
    "\n",
    "\n",
    "<img src=\"https://www.sos.sk/novinky/obr/obr2339_p094fca3946ce.jpg\"> \n",
    "\n",
    "Opisali oni taką komórkę nerwową jako prostą bramkę logiczną zawierającą binarne wyjścia. \n",
    "\n",
    "Do dendrytów dociera wiele sygnałów, które są integrowane w ciele komórki i, jeżeli energia impulsu przekracza określoną wartość graniczną zostaje wygenerowany sygnał wyjściowy przepuszczany przez akson. \n",
    "\n",
    "Kilka lat później Frank Rosenblatt na podstawie modelu neuronu MCP opublikował pierwszą koncepcję reguły uczenia perceprtronu (1957). Korzystając z tej reguły, Rosenblatt zaproponował algorytm zdolny do automatycznego uczenia się za pomocą optymalnych współczynników wag, które są przemnażane przez wartości wejściowe, co pozwala określić, czy neuron prześle dalej sygnał.\n",
    "\n",
    "W kontekście uczenia nadzorowanego i klasyfikacji taki algorytm może być wykorzystywany do przeridywania próbek przynależnych do różnych klas. \n",
    "\n",
    "\n",
    "W ujęciu matematycznym możemy przedstawić ten problem jako klasyfikację binarną, w której (dla uproszczenia) ustalmy dwie klasy: $-1, 1$.\n",
    "\n",
    "Następnie definiujemy funkcję aktywacji $\\phi(z)$, na którą składa się liniowa kombinacja określonych wartości wejściowych $x$ oraz powiązanego z nimi wektora wag $w$. $z$ nosi nazwę całkowitego pobudzenia układu $z=w_1 x_1+ \\dots + w_n x_n$\n",
    "\n",
    "Jeśli całkowite pobudzenie $z$ danej próbki $x^(i)$ jest wyższe od pewnej wartości granicznej $\\theta$, to przewidujemy, że dany obiekt przynależy do klasy pozytywnej $1$, w przeciwnym wypadku oznaczamy go jako $-1$. \n",
    "W algorytmie perceprtonu funkcja aktywacji $\\phi()$ jest prostą **funkcją skokową Heaviside'a**.\n",
    "\n",
    "\n",
    "Możemy dla uproszczenia przenieść wartość progową $\\theta$ na lewą stronę równania i zdefiniować początkową wagę jako $w_0=-\\theta$ a $x_0=1$, dzięki czemu całkowite pobudzenie $z$ przybierze prostszą postać \n",
    "\n",
    "$$z = w_0 x_0 + w_1 x_1 + \\dots + w_n x_n = w^T x$$ \n",
    "\n",
    "\n",
    "Podstawowym założeniem w neuronie MCP i modelu perceptronu progowego jest wprowadzenie uproszczonego mechanizmu naśladującego  działanie pojedynczej komórki nerwowej: albo zostaje ona uaktywniona, albo nie. \n",
    "\n",
    " - Schemat realizacji: \n",
    "\n",
    "1. Wprowadź wagi o wartości 0 lub niewielkich, losowych wartościach\n",
    "2. Dla każdej próbki uczącej $x^{(i)}$ wykonaj poniższe czynności:\n",
    "\n",
    "    a) Oblicz wartość wyjściową $\\hat{y}$\n",
    "\n",
    "    b) Zaktualizuj wagi\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akutalizacja wag\n",
    "\n",
    "$$ w_j := w_j + \\Delta w_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\Delta w_j = \\eta (y^{(i)}-\\hat{y}^{(i)})x_j^{(i)} $$\n",
    "\n",
    "gdzie $\\eta$ `Learning rate`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja binarna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dwa wiersze danych realizujące pierwszą klasę\n",
    "x1 = [1,2]\n",
    "x2 = [3,4]\n",
    "# dwa wiersze danych realizujące drugą klasę \n",
    "y1 = [-1,-1]\n",
    "y2 = [1,1]\n",
    "plt.scatter(x1, y1, marker='o', color='r')\n",
    "plt.scatter(x2, y2, marker='x', color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nasze dane w postaci macierzowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1],[2],[3],[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dodajemy kolumnę 1 aby przesunąć wartość progową z $\\theta$ na 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(1+X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nasza pierwsza klasa - Perceprton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \n",
    "    def __init__(self,eta=0.01, n_iter=10):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.w_ = np.zeros(1+X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X,y):\n",
    "                print(xi, target)\n",
    "                update = self.eta*(target-self.predict(xi))\n",
    "                print(update)\n",
    "                self.w_[1:] += update*xi\n",
    "                self.w_[0] += update\n",
    "                print(self.w_)\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        return np.dot(X, self.w_[1:])+self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.where(self.net_input(X)>=0.0,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Perceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1],[2],[3],[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [-1,-1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -1\n",
      "-0.02\n",
      "[-0.02 -0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.02 -0.02]\n",
      "[3] 1\n",
      "0.02\n",
      "[0.   0.04]\n",
      "[4] 1\n",
      "0.0\n",
      "[0.   0.04]\n",
      "[1] -1\n",
      "-0.02\n",
      "[-0.02  0.02]\n",
      "[2] -1\n",
      "-0.02\n",
      "[-0.04 -0.02]\n",
      "[3] 1\n",
      "0.02\n",
      "[-0.02  0.04]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.02  0.04]\n",
      "[1] -1\n",
      "-0.02\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[1] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[2] -1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[3] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n",
      "[4] 1\n",
      "0.0\n",
      "[-0.04  0.02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Perceptron at 0x11d9e4430>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.04, 0.06, 0.08])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(X,a.w_[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.04"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.w_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie \n",
    "\n",
    "Napisz Perceptrona w wersji z losowymi, małymi wagami "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
